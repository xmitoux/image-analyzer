"""
Google Cloud Vision API ã‚µãƒ¼ãƒ“ã‚¹
"""
import base64
import io
import os
from typing import Dict, List, Optional, Union

from django.conf import settings
from google.cloud import vision


def analyze_image_objects_for_classification(image_content: Union[bytes, str]) -> Dict:
    """
    Vision APIã‚’ä½¿ç”¨ã—ã¦ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡ºã‚’è¡Œã„ã€æœ€ä¸Šä½ã®çµæœã‚’ãƒ©ãƒ™ãƒ«ãƒã‚¹ã‚¿ã¨ç…§åˆã—ã¦classificationã‚’è¿”ã™

    Args:
        image_content: ç”»åƒã®ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯base64æ–‡å­—åˆ—

    Returns:
        {
            'success': bool,
            'message': str,
            'estimated_data': {
                'class': int,
                'confidence': float
            }
        }
    """
    try:
        from .models import ObjectLabel

        # Google Cloudèªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if not os.getenv('GOOGLE_APPLICATION_CREDENTIALS'):
            return {
                'success': False,
                'message': 'Google Cloud credentials not configured',
                'estimated_data': {}
            }

        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        if isinstance(image_content, str):
            # data URLå½¢å¼ã®å ´åˆã€ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»
            if image_content.startswith('data:image/'):
                image_content = image_content.split(',', 1)[1]

            try:
                image_content = base64.b64decode(image_content)
            except Exception as decode_error:
                return {
                    'success': False,
                    'message': f'Invalid base64 data: {str(decode_error)}',
                    'estimated_data': {}
                }

        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        if len(image_content) == 0:
            return {
                'success': False,
                'message': 'Empty image data',
                'estimated_data': {}
            }

        if len(image_content) > 20 * 1024 * 1024:  # 20MBåˆ¶é™
            return {
                'success': False,
                'message': 'Image data too large (max 20MB)',
                'estimated_data': {}
            }

        # Vision APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
        client = vision.ImageAnnotatorClient()
        image = vision.Image(content=image_content)

        # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡ºå®Ÿè¡Œ
        response = client.object_localization(image=image)
        objects = response.localized_object_annotations

        if response.error.message:
            return {
                'success': False,
                'message': f'Vision API Error: {response.error.message}',
                'estimated_data': {}
            }

        if not objects:
            return {
                'success': False,
                'message': 'No objects detected',
                'estimated_data': {}
            }

        # ã‚¹ã‚³ã‚¢ãŒæœ€å¤§ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
        top_object = max(objects, key=lambda obj: obj.score)
        object_name = top_object.name.lower()  # å°æ–‡å­—ã§çµ±ä¸€
        confidence = top_object.score

        print(
            f"ğŸ” Top detected object: {object_name} (confidence: {confidence:.4f})")

        # ãƒ©ãƒ™ãƒ«ãƒã‚¹ã‚¿ã§ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåã‚’æ¤œç´¢ãƒ»ç™»éŒ²
        object_label, created = ObjectLabel.objects.get_or_create(
            name=object_name,
            defaults={'name': object_name}
        )

        if created:
            print(
                f"ğŸ†• New label registered: {object_name} (ID: {object_label.id})")
        else:
            print(
                f"ğŸ” Existing label found: {object_name} (ID: {object_label.id})")

        return {
            'success': True,
            'message': 'success',
            'estimated_data': {
                'class': object_label.id,
                'confidence': round(confidence, 4)
            }
        }

    except Exception as e:
        return {
            'success': False,
            'message': f'Analysis failed: {str(e)}',
            'estimated_data': {}
        }


class VisionAPIService:
    """Google Cloud Vision API ã‚’ä½¿ç”¨ã—ãŸç”»åƒè§£æã‚µãƒ¼ãƒ“ã‚¹"""

    def __init__(self):
        self.client = vision.ImageAnnotatorClient()

    @staticmethod
    def run_quickstart() -> Dict:
        """Provides a quick start example for Cloud Vision."""
        try:
            # Instantiates a client
            client = vision.ImageAnnotatorClient()

            # The URI of the image file to annotate
            file_uri = "gs://cloud-samples-data/vision/label/wakeupcat.jpg"

            image = vision.Image()
            image.source.image_uri = file_uri

            # Performs label detection on the image file
            response = client.label_detection(image=image)
            labels = response.label_annotations

            if response.error.message:
                return {
                    'success': False,
                    'error': f'Vision API Error: {response.error.message}'
                }

            result_labels = []
            print("Labels:")
            for label in labels:
                print(f"- {label.description} (confidence: {label.score:.2f})")
                result_labels.append({
                    'description': label.description,
                    'score': label.score
                })

            return {
                'success': True,
                'labels': result_labels,
                'message': f'Found {len(result_labels)} labels'
            }

        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

    def analyze_image(self, image_content: Union[bytes, str],
                      analysis_types: Optional[List[str]] = None) -> Dict:
        """
        ç”»åƒã‚’è§£æã™ã‚‹

        Args:
            image_content: ç”»åƒã®ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯base64æ–‡å­—åˆ—
            analysis_types: å®Ÿè¡Œã™ã‚‹è§£æã®ã‚¿ã‚¤ãƒ—ãƒªã‚¹ãƒˆ
                          ['labels', 'text', 'faces', 'objects', 'landmarks']

        Returns:
            è§£æçµæœã®è¾æ›¸
        """
        if analysis_types is None:
            analysis_types = ['labels', 'text']

        try:
            # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            if isinstance(image_content, str):
                # base64æ–‡å­—åˆ—ã®å ´åˆã€data URLãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»
                if image_content.startswith('data:image/'):
                    # data:image/jpeg;base64,... å½¢å¼ã®å ´åˆ
                    image_content = image_content.split(',', 1)[1]

                try:
                    image_content = base64.b64decode(image_content)
                except Exception as decode_error:
                    raise Exception(
                        f"Invalid base64 data: {str(decode_error)}")

            # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            if len(image_content) == 0:
                raise Exception("Empty image data")

            if len(image_content) > 20 * 1024 * 1024:  # 20MBåˆ¶é™
                raise Exception("Image data too large (max 20MB)")

            image = vision.Image(content=image_content)

            results = {}

            # ãƒ©ãƒ™ãƒ«æ¤œå‡º
            if 'labels' in analysis_types:
                results['labels'] = self._detect_labels(image)

            # ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡º
            if 'text' in analysis_types:
                results['text'] = self._detect_text(image)

            # é¡”æ¤œå‡º
            if 'faces' in analysis_types:
                results['faces'] = self._detect_faces(image)

            # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡º
            if 'objects' in analysis_types:
                results['objects'] = self._detect_objects(image)

            # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡º
            if 'landmarks' in analysis_types:
                results['landmarks'] = self._detect_landmarks(image)

            return {
                'success': True,
                'results': results
            }

        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

    def _detect_labels(self, image: vision.Image) -> List[Dict]:
        """ãƒ©ãƒ™ãƒ«æ¤œå‡º"""
        response = self.client.label_detection(image=image)
        labels = response.label_annotations

        if response.error.message:
            raise Exception(f'{response.error.message}')

        return [{
            'description': label.description,
            'score': label.score,
            'confidence': label.score
        } for label in labels]

    def _detect_text(self, image: vision.Image) -> Dict:
        """ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡º"""
        response = self.client.text_detection(image=image)
        texts = response.text_annotations

        if response.error.message:
            raise Exception(f'{response.error.message}')

        if texts:
            # æœ€åˆã®è¦ç´ ã¯å…¨ä½“ã®ãƒ†ã‚­ã‚¹ãƒˆ
            full_text = texts[0].description
            # æ®‹ã‚Šã¯å€‹åˆ¥ã®æ–‡å­—/å˜èª
            words = [{
                'text': text.description,
                'bounds': {
                    'vertices': [
                        {'x': vertex.x, 'y': vertex.y}
                        for vertex in text.bounding_poly.vertices
                    ]
                }
            } for text in texts[1:]]

            return {
                'full_text': full_text,
                'words': words
            }

        return {'full_text': '', 'words': []}

    def _detect_faces(self, image: vision.Image) -> List[Dict]:
        """é¡”æ¤œå‡º"""
        response = self.client.face_detection(image=image)
        faces = response.face_annotations

        if response.error.message:
            raise Exception(f'{response.error.message}')

        return [{
            'confidence': face.detection_confidence,
            'joy_likelihood': face.joy_likelihood.name,
            'sorrow_likelihood': face.sorrow_likelihood.name,
            'anger_likelihood': face.anger_likelihood.name,
            'surprise_likelihood': face.surprise_likelihood.name,
            'bounds': {
                'vertices': [
                    {'x': vertex.x, 'y': vertex.y}
                    for vertex in face.bounding_poly.vertices
                ]
            }
        } for face in faces]

    def _detect_objects(self, image: vision.Image) -> List[Dict]:
        """ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡º"""
        response = self.client.object_localization(image=image)
        objects = response.localized_object_annotations

        if response.error.message:
            raise Exception(f'{response.error.message}')

        return [{
            'name': obj.name,
            'score': obj.score,
            'bounds': {
                'vertices': [
                    {'x': vertex.x, 'y': vertex.y}
                    for vertex in obj.bounding_poly.normalized_vertices
                ]
            }
        } for obj in objects]

    def _detect_landmarks(self, image: vision.Image) -> List[Dict]:
        """ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡º"""
        response = self.client.landmark_detection(image=image)
        landmarks = response.landmark_annotations

        if response.error.message:
            raise Exception(f'{response.error.message}')

        return [{
            'description': landmark.description,
            'score': landmark.score,
            'locations': [{
                'latitude': location.lat_lng.latitude,
                'longitude': location.lat_lng.longitude
            } for location in landmark.locations]
        } for landmark in landmarks]


def analyze_image_with_vision_api(image_content: Union[bytes, str],
                                  analysis_types: Optional[List[str]] = None) -> Dict:
    """
    Vision APIã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‚’è§£æã™ã‚‹ä¾¿åˆ©é–¢æ•°

    Args:
        image_content: ç”»åƒã®ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯base64æ–‡å­—åˆ—
        analysis_types: å®Ÿè¡Œã™ã‚‹è§£æã®ã‚¿ã‚¤ãƒ—ãƒªã‚¹ãƒˆ

    Returns:
        è§£æçµæœã®è¾æ›¸
    """
    service = VisionAPIService()
    return service.analyze_image(image_content, analysis_types)
